# First Install ffmpeg and add bin folder to env path
#
# Then you must install Ollama, then pull a model of your choice via CLI. I went with llama3.2 "ollama pull llama3.2"
#
# If you're planning in using your Nvidia GPU, this will require Python 3.10 and a CUDA 12.1 compatible Nvidia gpu
# 
# If you haven't already set up a Python 3.10 venv, run this:
#   python3.10 -m venv venv
#   OR
#   py -3.10 -m venv venv
#
#   venv\scripts\activate
#
# If you don't have CUDA 12.1 installed you will need to install it from
#    https://developer.nvidia.com/cuda-toolkit-archive
#
# You then need to install Then install PyTorch 2.1.2 for CUDA 12.1 with:
#   pip install torch==2.1.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121
#
#  pip install -r requirements.txt
#  python -m pip install -r requirements.txt

tqdm==4.66.2
rich==13.7.0
numpy==1.26.4
platformdirs==4.2.0
ctranslate2==4.0.0
tokenizers==0.15.2
huggingface-hub==0.20.3
accelerate==0.25.0
optimum==1.17.1
transformers==4.36.1
openai-whisper==20231117
nvidia-ml-py==12.535.133
whisper-s2t==1.3.1
ollama==0.4.7
sounddevice==0.5.1
soundfile==0.13.1
openpyxl==3.1.5
